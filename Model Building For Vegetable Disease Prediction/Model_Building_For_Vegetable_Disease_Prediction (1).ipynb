{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Building For Vegetable Disease Prediction**\n"
      ],
      "metadata": {
        "id": "YUrAsi443lsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import The Libraries** "
      ],
      "metadata": {
        "id": "SmA8Sau80vGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten"
      ],
      "metadata": {
        "id": "QZWNDvWH0xvO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IMAGE PREPROCESSING**"
      ],
      "metadata": {
        "id": "dhbg-YG907bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "h_QP6bWs1AtC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2,zoom_range = 0.2,horizontal_flip = True)"
      ],
      "metadata": {
        "id": "4tVAjx5h13Ro"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1)"
      ],
      "metadata": {
        "id": "FPna67Me16Qc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train= train_datagen.flow_from_directory('/content/drive/MyDrive/Veg-dataset/Veg-dataset/train_set',batch_size=32,target_size=(128,128),\n",
        "                                         color_mode='rgb',class_mode='categorical')\n",
        "x_test = test_datagen.flow_from_directory('/content/drive/MyDrive/Veg-dataset/Veg-dataset/test_set',batch_size=32,target_size=(128,128),\n",
        "                                         color_mode='rgb',class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyqUQy2V19BU",
        "outputId": "2a63dbd1-266f-4c37-8102-3f1b7dc89cde"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 11430 images belonging to 9 classes.\n",
            "Found 3416 images belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import Sequence"
      ],
      "metadata": {
        "id": "VDxqoNbz2B8b"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Initializing The Model**"
      ],
      "metadata": {
        "id": "OAQoS3z22IuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()"
      ],
      "metadata": {
        "id": "aC_Ot3HV2NeJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ADD CNNLayers**"
      ],
      "metadata": {
        "id": "UUPi7oDS2SFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Convolution2D(32,(3,3),input_shape = (128,128,3),activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Flatten())"
      ],
      "metadata": {
        "id": "SndE4ezQ2WHJ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Add Dense Layers**"
      ],
      "metadata": {
        "id": "4dmrH2rL2bxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(300,  'relu'))\n",
        "model.add(Dense(150, 'relu'))\n",
        "model.add(Dense(75, 'relu'))\n",
        "model.add(Dense(9,  'softmax', ))\n"
      ],
      "metadata": {
        "id": "SyBRiUPW2fgW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train And Save The Model**"
      ],
      "metadata": {
        "id": "IbnoF1kN2mdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss = \"categorical_crossentropy\" , metrics =['accuracy'])"
      ],
      "metadata": {
        "id": "5qxDYHFF2qDs"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZqUfMji26YL",
        "outputId": "ca5bf1c1-2c71-4996-ad21-cd837e4a1cdf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 126, 126, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 63, 63, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 127008)            0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 300)               38102700  \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 150)               45150     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 75)                11325     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 9)                 684       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,160,755\n",
            "Trainable params: 38,160,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,epochs=10,steps_per_epoch=89,validation_data = x_test, validation_steps = 27)\n",
        "\n",
        "\n",
        "model.save(\"veg.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a2x8tq0Sy0n",
        "outputId": "be4a7a2a-42ed-4056-a75c-02ab68246bf4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "89/89 [==============================] - 718s 8s/step - loss: 1.4285 - accuracy: 0.5103 - val_loss: 398.4555 - val_accuracy: 0.3611\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 512s 6s/step - loss: 0.9607 - accuracy: 0.6552 - val_loss: 883.0972 - val_accuracy: 0.2697\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 361s 4s/step - loss: 0.7985 - accuracy: 0.7229 - val_loss: 664.0219 - val_accuracy: 0.3275\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 290s 3s/step - loss: 0.6901 - accuracy: 0.7598 - val_loss: 870.4464 - val_accuracy: 0.2859\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 208s 2s/step - loss: 0.6114 - accuracy: 0.7802 - val_loss: 709.7632 - val_accuracy: 0.3542\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 183s 2s/step - loss: 0.5603 - accuracy: 0.7978 - val_loss: 842.9805 - val_accuracy: 0.2384\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 148s 2s/step - loss: 0.5167 - accuracy: 0.8195 - val_loss: 1794.7992 - val_accuracy: 0.1296\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 118s 1s/step - loss: 0.4628 - accuracy: 0.8385 - val_loss: 1593.1969 - val_accuracy: 0.1516\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 103s 1s/step - loss: 0.4795 - accuracy: 0.8304 - val_loss: 1793.0253 - val_accuracy: 0.1551\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 94s 1s/step - loss: 0.3958 - accuracy: 0.8575 - val_loss: 1651.8546 - val_accuracy: 0.1505\n"
          ]
        }
      ]
    }
  ]
}