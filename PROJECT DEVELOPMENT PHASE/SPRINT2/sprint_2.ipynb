{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lNm8NCSWLvlq"
      },
      "outputs": [],
      "source": [
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2,zoom_range = 0.2,horizontal_flip = True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train= train_datagen.flow_from_directory('/content/drive/MyDrive/fruit-dataset/fruit-dataset/train',batch_size=32,target_size=(128,128),\n",
        "                                         color_mode='rgb',class_mode='categorical')\n",
        "x_test = test_datagen.flow_from_directory('/content/drive/MyDrive/fruit-dataset/fruit-dataset/test',batch_size=32,target_size=(128,128),\n",
        "                                         color_mode='rgb',class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNSIMhI9bvIb",
        "outputId": "c3b8bdd3-f1df-4636-9420-4f424feba6bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5384 images belonging to 6 classes.\n",
            "Found 1686 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2,zoom_range = 0.2,horizontal_flip = True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1)\n",
        "\n",
        "x_train= train_datagen.flow_from_directory('/content/drive/MyDrive/fruit-dataset/fruit-dataset/train',batch_size=32,target_size=(128,128),\n",
        "                                         color_mode='rgb',class_mode='categorical')\n",
        "x_test = test_datagen.flow_from_directory('/content/drive/MyDrive/fruit-dataset/fruit-dataset/test',batch_size=32,target_size=(128,128),\n",
        "                                         color_mode='rgb',class_mode='categorical')\n",
        "from tensorflow.keras.utils import Sequence\n",
        "model=Sequential()\n",
        "model.add(Convolution2D(32,(3,3),input_shape = (128,128,3),activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(40,  'relu'))\n",
        "model.add(Dense(20, 'relu'))\n",
        "model.add(Dense(6,  'softmax', ))\n",
        "\n",
        "model.compile(optimizer='adam', loss = \"categorical_crossentropy\" , metrics =['accuracy'])\n",
        "# Visualize Model\n",
        "model.summary()\n",
        "model.fit(x_train,epochs=20,steps_per_epoch=89,validation_data = x_test, validation_steps = 27)\n",
        "\n",
        "\n",
        "model.save(\"fruit.h5\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhYLrxI8JEC8",
        "outputId": "a6e5761c-1a2f-4114-ea33-e54ee097ccb6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5384 images belonging to 6 classes.\n",
            "Found 1686 images belonging to 6 classes.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 127008)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 40)                5080360   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                820       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 126       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,082,202\n",
            "Trainable params: 5,082,202\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "89/89 [==============================] - 717s 8s/step - loss: 1.3023 - accuracy: 0.5609 - val_loss: 59.3136 - val_accuracy: 0.7199\n",
            "Epoch 2/20\n",
            "89/89 [==============================] - 354s 4s/step - loss: 0.6571 - accuracy: 0.7882 - val_loss: 60.1567 - val_accuracy: 0.7824\n",
            "Epoch 3/20\n",
            "89/89 [==============================] - 183s 2s/step - loss: 0.4134 - accuracy: 0.8615 - val_loss: 124.2583 - val_accuracy: 0.6863\n",
            "Epoch 4/20\n",
            "89/89 [==============================] - 108s 1s/step - loss: 0.3113 - accuracy: 0.8982 - val_loss: 615.5879 - val_accuracy: 0.4329\n",
            "Epoch 5/20\n",
            "89/89 [==============================] - 75s 836ms/step - loss: 0.2583 - accuracy: 0.9129 - val_loss: 541.0003 - val_accuracy: 0.4641\n",
            "Epoch 6/20\n",
            "89/89 [==============================] - 60s 673ms/step - loss: 0.2481 - accuracy: 0.9112 - val_loss: 663.6074 - val_accuracy: 0.4630\n",
            "Epoch 7/20\n",
            "89/89 [==============================] - 54s 599ms/step - loss: 0.2167 - accuracy: 0.9252 - val_loss: 504.1471 - val_accuracy: 0.4850\n",
            "Epoch 8/20\n",
            "89/89 [==============================] - 52s 584ms/step - loss: 0.2076 - accuracy: 0.9274 - val_loss: 554.8959 - val_accuracy: 0.4618\n",
            "Epoch 9/20\n",
            "89/89 [==============================] - 51s 574ms/step - loss: 0.2308 - accuracy: 0.9200 - val_loss: 591.8171 - val_accuracy: 0.4618\n",
            "Epoch 10/20\n",
            "89/89 [==============================] - 50s 564ms/step - loss: 0.1834 - accuracy: 0.9402 - val_loss: 927.3312 - val_accuracy: 0.4028\n",
            "Epoch 11/20\n",
            "89/89 [==============================] - 50s 558ms/step - loss: 0.1923 - accuracy: 0.9361 - val_loss: 726.0818 - val_accuracy: 0.4560\n",
            "Epoch 12/20\n",
            "89/89 [==============================] - 50s 556ms/step - loss: 0.1800 - accuracy: 0.9417 - val_loss: 971.6089 - val_accuracy: 0.4120\n",
            "Epoch 13/20\n",
            "89/89 [==============================] - 50s 555ms/step - loss: 0.1912 - accuracy: 0.9364 - val_loss: 635.0948 - val_accuracy: 0.5255\n",
            "Epoch 14/20\n",
            "89/89 [==============================] - 49s 553ms/step - loss: 0.1511 - accuracy: 0.9479 - val_loss: 644.2640 - val_accuracy: 0.4965\n",
            "Epoch 15/20\n",
            "89/89 [==============================] - 50s 560ms/step - loss: 0.1573 - accuracy: 0.9473 - val_loss: 631.8009 - val_accuracy: 0.5961\n",
            "Epoch 16/20\n",
            "89/89 [==============================] - 50s 556ms/step - loss: 0.1383 - accuracy: 0.9508 - val_loss: 679.6030 - val_accuracy: 0.5475\n",
            "Epoch 17/20\n",
            "89/89 [==============================] - 50s 556ms/step - loss: 0.1452 - accuracy: 0.9515 - val_loss: 903.8804 - val_accuracy: 0.4271\n",
            "Epoch 18/20\n",
            "89/89 [==============================] - 50s 556ms/step - loss: 0.1486 - accuracy: 0.9498 - val_loss: 661.1855 - val_accuracy: 0.6146\n",
            "Epoch 19/20\n",
            "89/89 [==============================] - 49s 553ms/step - loss: 0.1251 - accuracy: 0.9547 - val_loss: 1024.8682 - val_accuracy: 0.4225\n",
            "Epoch 20/20\n",
            "89/89 [==============================] - 50s 557ms/step - loss: 0.1289 - accuracy: 0.9568 - val_loss: 722.6586 - val_accuracy: 0.4907\n"
          ]
        }
      ]
    }
  ]
}